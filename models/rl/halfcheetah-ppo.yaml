halfcheetah-ppo:
    env: HalfCheetah-v2
    run: PPO
    stop:
        episode_reward_mean: 9800
        time_total_s: 10800
    config:
        # Works for both torch and tf.
        framework: torch
        gamma: 0.99
        lambda: 0.95
        kl_coeff: 1.0
        num_sgd_iter: 32
        lr: .0003
        vf_loss_coeff: 0.5
        clip_param: 0.2
        sgd_minibatch_size: 4096
        train_batch_size: 65536
        grad_clip: 0.5
        batch_mode: truncate_episodes
        observation_filter: MeanStdFilter
        num_gpus: 1